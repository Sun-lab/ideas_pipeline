devtools::install_github('churchill-lab/scRATE')
library(scRATE)
install.packages(devtools)
install.packages("devtools")
R.section
R.session
R.version
devtools::install_github('churchill-lab/scRATE')
library(scRATE)
version()
install.packages('hdf5r')
install.packages('hdf5r')
library(scRATE)
library(loomR)
install.packages('hdf5r')
devtools::install_github('churchill-lab/scRATE')
library(scRATE)
library(loomR)
devtools::install_github(repo = "mojaveazure/loomR", ref = "develop")
devtools::install_github('churchill-lab/scRATE')
library(scRATE)
install.packages('hdf5r')
devtools::install_github(repo = "mojaveazure/loomR", ref = "develop")
library(scRATE)
library(loomR)
devtools::install_github('churchill-lab/scRATE')
library(scRATE)
version()
library(ipw)
library("ipw")
data(basdat)
View(basdat)
data(haartdat)
View(haartdat)
data(healthdat)
View(haartdat)
data(healthdat)
View(healthdat)
?ipwpoint
library("ipw")
data(basdat)
#Simulate data with continuous confounder and outcome, binomial exposure.
#Marginal causal effect of exposure on outcome: 10.
n <- 1000
simdat <- data.frame(l = rnorm(n, 10, 5))
a.lin <- simdat$l - 10
pa <- exp(a.lin)/(1 + exp(a.lin))
simdat$a <- rbinom(n, 1, prob = pa)
simdat$y <- 10*simdat$a + 0.5*simdat$l + rnorm(n, -10, 5)
simdat[1:5,]
#Estimate ipw weights.
temp <- ipwpoint(
exposure = a,
family = "binomial",
link = "logit",
numerator = ~ 1,
denominator = ~ l,
data = simdat)
summary(temp$ipw.weights)
#Plot inverse probability weights
graphics.off()
ipwplot(weights = temp$ipw.weights, logscale = FALSE,
main = "Stabilized weights", xlim = c(0, 8))
#Examine numerator and denominator models.
summary(temp$num.mod)
summary(temp$den.mod)
#Paste inverse probability weights
simdat$sw <- temp$ipw.weights
#Marginal structural model for the causal effect of a on y
#corrected for confounding by l using inverse probability weighting
#with robust standard error from the survey package.
require("survey")
msm <- (svyglm(y ~ a, design = svydesign(~ 1, weights = ~ sw,
data = simdat)))
coef(msm)
confint(msm)
## Not run:
#Compute basic bootstrap confidence interval .
require(boot)
boot.fun <- function(dat, index){
coef(glm(
formula = y ~ a,
data = dat[index,],
weights = ipwpoint(
exposure = a,
family = "gaussian",
numerator = ~ 1,
denominator = ~ l,
data = dat[index,])$ipw.weights))[2]
}
bootres <- boot(simdat, boot.fun, 499);bootres
boot.ci(bootres, type = "basic")
head(haartdat)
#EXAMPLE 2
data(basdat)
data(timedat)
#Aim: to model the causal effect of active tuberculosis (TB) on mortality.
#Longitudinal CD4 is a confounder as well as intermediate for the effect of TB.
#process original measurements
#check for ties (not allowed)
table(duplicated(timedat[,c("id", "fuptime")]))
#take square root of CD4 because of skewness
timedat$cd4.sqrt <- sqrt(timedat$cd4count)
#add TB time to dataframe
timedat <- merge(timedat, basdat[,c("id", "Ttb")], by = "id", all.x = TRUE)
#compute TB status
timedat$tb.lag <- ifelse(with(timedat, !is.na(Ttb) & fuptime > Ttb), 1, 0)
#longitudinal CD4-model
require(nlme)
cd4.lme <- lme(cd4.sqrt ~ fuptime + tb.lag, random = ~ fuptime | id,
data = timedat)
#build new dataset:
#rows corresponding to TB-status switches, and individual end times
times <- sort(unique(c(basdat$Ttb, basdat$Tend)))
startstop <- data.frame(
id = rep(basdat$id, each = length(times)),
fuptime = rep(times, nrow(basdat)))
#add baseline data to dataframe
startstop <- merge(startstop, basdat, by = "id", all.x = TRUE)
#limit individual follow-up using Tend
startstop <- startstop[with(startstop, fuptime <= Tend),]
startstop$tstart <- tstartfun(id, fuptime, startstop) #compute tstart (?tstartfun)
#indicate TB status
startstop$tb <- ifelse(with(startstop, !is.na(Ttb) & fuptime >= Ttb), 1, 0)
#indicate TB status at previous time point
startstop$tb.lag <- ifelse(with(startstop, !is.na(Ttb) & fuptime > Ttb), 1, 0)
#indicate death
startstop$event <- ifelse(with(startstop, !is.na(Tdeath) & fuptime >= Tdeath),
1, 0)
#impute CD4, based on TB status at previous time point.
startstop$cd4.sqrt <- predict(cd4.lme, newdata = data.frame(id = startstop$id,
fuptime = startstop$fuptime, tb.lag = startstop$tb.lag))
#compute inverse probability weights
require(survival)
temp <- ipwtm(
exposure = tb,
family = "survival",
numerator = ~ 1,
denominator = ~ cd4.sqrt,
id = id,
tstart = tstart,
timevar = fuptime,
type = "first",
data = startstop)
summary(temp$ipw.weights)
ipwplot(weights = temp$ipw.weights, timevar = startstop$fuptime, binwidth = 100)
#models
#IPW-fitted MSM, using cluster() to obtain robust standard error estimate
summary(coxph(Surv(tstart, fuptime, event) ~ tb + cluster(id),
data = startstop, weights = temp$ipw.weights))
#unadjusted
summary(coxph(Surv(tstart, fuptime, event) ~ tb, data = startstop))
#adjusted using conditioning: part of the effect of TB is adjusted away
summary(coxph(Surv(tstart, fuptime, event) ~ tb + cd4.sqrt, data = startstop))
## Not run:
#compute bootstrap CI for TB parameter (takes a few hours)
#taking into account the uncertainty introduced by modelling longitudinal CD4
#taking into account the uncertainty introduced by estimating the inverse probability weights
#robust with regard to weights unequal to 1
require(boot)
head(timedat)
head(haartdat)
hist(haarti )
hist(haartind)
hist(haartdat$haartind)
ls()
EE_index   = gene_index$EE_index
args = commandArgs(trailingOnly=TRUE)
args
if (length(args) < 5) {
message("no enough arguments, using default values")
r_mean   = 1.2     # The expected fold-changes in mean
r_var    = 1.5     # The expected fold-changes in variances
ncase    = 13      # case individuals
nctrl    = 10      # control individuals
ncell    = 360    # numbers of cells collected from each individuals.
} else{
for(i in 1:length(args)){
eval(parse(text=args[[i]]))
}
}
if(ncell == 0){
UNEQ_N_CELL = TRUE
}else{
UNEQ_N_CELL = FALSE
}
if(UNEQ_N_CELL){
config = sprintf("ncase_%d_nctrl_%d_unequal_n_cell", ncase, nctrl)
}else{
config = sprintf("ncase_%d_nctrl_%d_ncell_%d", ncase, nctrl, ncell)
}
config = sprintf("%s_fold_mean_%.1f_var_%.1f", config, r_mean, r_var)
config
nCore = 6      # number of cores for multi-core computation
nall  = ncase + nctrl
library(MASS)
library(emdbook)
library(moments)
library(MAST)
library(lme4)
library(DESeq2)
library(doParallel)
library(foreach)
library(doRNG)
library(MiRKAT)
library(reticulate)
library(transport)
library(data.table)
library(pryr)
library(ggplot2)
library(ggpubr)
theme_set(theme_bw())
library(ideas)
registerDoParallel(cores=nCore)
options(mc.cores=nCore)
sim_data     = readRDS(sprintf("data/sim_data_%s.rds", config))
count_matrix = sim_data$count_matrix
meta_cell    = sim_data$meta_cell
meta_ind     = sim_data$meta_ind
gene_index   = sim_data$gene_index
count_matrix[1:10,1:10]
setwd("~/Desktop/github/ideas/Autism")
sim_data     = readRDS(sprintf("data/sim_data_%s.rds", config))
setwd("~/Desktop/github/ideas/simulation")
sim_data     = readRDS(sprintf("data/sim_data_%s.rds", config))
count_matrix = sim_data$count_matrix
meta_cell    = sim_data$meta_cell
meta_ind     = sim_data$meta_ind
gene_index   = sim_data$gene_index
count_matrix[1:10,1:10]
count_matrix=count_matrix[1:500,1:1000]
count_matrix_saver = saver(count_matrix,estimates.only = TRUE)
library(SAVER)
count_matrix_saver = saver(count_matrix,estimates.only = TRUE)
count_matrix_saver1 = saver(count_matrix)
count_matrix=count_matrix[1:100,1:500]
count_matrix_saver1 = saver(count_matrix)
count_matrix_saver = saver(count_matrix,estimates.only = TRUE)
count_matrix_saver1 = saver(count_matrix)
View(count_matrix_saver)
View(count_matrix)
count_matrix_saver[1:3,1:2]
type(count_matrix_saver)
type(count_matrix)
class(count_matrix)
class(count_matrix_saver)
